{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "data": {
      "text/plain": "['AlexNet',\n 'AlexNet_Weights',\n 'ConvNeXt',\n 'ConvNeXt_Base_Weights',\n 'ConvNeXt_Large_Weights',\n 'ConvNeXt_Small_Weights',\n 'ConvNeXt_Tiny_Weights',\n 'DenseNet',\n 'DenseNet121_Weights',\n 'DenseNet161_Weights',\n 'DenseNet169_Weights',\n 'DenseNet201_Weights',\n 'EfficientNet',\n 'EfficientNet_B0_Weights',\n 'EfficientNet_B1_Weights',\n 'EfficientNet_B2_Weights',\n 'EfficientNet_B3_Weights',\n 'EfficientNet_B4_Weights',\n 'EfficientNet_B5_Weights',\n 'EfficientNet_B6_Weights',\n 'EfficientNet_B7_Weights',\n 'EfficientNet_V2_L_Weights',\n 'EfficientNet_V2_M_Weights',\n 'EfficientNet_V2_S_Weights',\n 'GoogLeNet',\n 'GoogLeNetOutputs',\n 'GoogLeNet_Weights',\n 'Inception3',\n 'InceptionOutputs',\n 'Inception_V3_Weights',\n 'MNASNet',\n 'MNASNet0_5_Weights',\n 'MNASNet0_75_Weights',\n 'MNASNet1_0_Weights',\n 'MNASNet1_3_Weights',\n 'MaxVit',\n 'MaxVit_T_Weights',\n 'MobileNetV2',\n 'MobileNetV3',\n 'MobileNet_V2_Weights',\n 'MobileNet_V3_Large_Weights',\n 'MobileNet_V3_Small_Weights',\n 'RegNet',\n 'RegNet_X_16GF_Weights',\n 'RegNet_X_1_6GF_Weights',\n 'RegNet_X_32GF_Weights',\n 'RegNet_X_3_2GF_Weights',\n 'RegNet_X_400MF_Weights',\n 'RegNet_X_800MF_Weights',\n 'RegNet_X_8GF_Weights',\n 'RegNet_Y_128GF_Weights',\n 'RegNet_Y_16GF_Weights',\n 'RegNet_Y_1_6GF_Weights',\n 'RegNet_Y_32GF_Weights',\n 'RegNet_Y_3_2GF_Weights',\n 'RegNet_Y_400MF_Weights',\n 'RegNet_Y_800MF_Weights',\n 'RegNet_Y_8GF_Weights',\n 'ResNeXt101_32X8D_Weights',\n 'ResNeXt101_64X4D_Weights',\n 'ResNeXt50_32X4D_Weights',\n 'ResNet',\n 'ResNet101_Weights',\n 'ResNet152_Weights',\n 'ResNet18_Weights',\n 'ResNet34_Weights',\n 'ResNet50_Weights',\n 'ShuffleNetV2',\n 'ShuffleNet_V2_X0_5_Weights',\n 'ShuffleNet_V2_X1_0_Weights',\n 'ShuffleNet_V2_X1_5_Weights',\n 'ShuffleNet_V2_X2_0_Weights',\n 'SqueezeNet',\n 'SqueezeNet1_0_Weights',\n 'SqueezeNet1_1_Weights',\n 'SwinTransformer',\n 'Swin_B_Weights',\n 'Swin_S_Weights',\n 'Swin_T_Weights',\n 'Swin_V2_B_Weights',\n 'Swin_V2_S_Weights',\n 'Swin_V2_T_Weights',\n 'VGG',\n 'VGG11_BN_Weights',\n 'VGG11_Weights',\n 'VGG13_BN_Weights',\n 'VGG13_Weights',\n 'VGG16_BN_Weights',\n 'VGG16_Weights',\n 'VGG19_BN_Weights',\n 'VGG19_Weights',\n 'ViT_B_16_Weights',\n 'ViT_B_32_Weights',\n 'ViT_H_14_Weights',\n 'ViT_L_16_Weights',\n 'ViT_L_32_Weights',\n 'VisionTransformer',\n 'Weights',\n 'WeightsEnum',\n 'Wide_ResNet101_2_Weights',\n 'Wide_ResNet50_2_Weights',\n '_GoogLeNetOutputs',\n '_InceptionOutputs',\n '__builtins__',\n '__cached__',\n '__doc__',\n '__file__',\n '__loader__',\n '__name__',\n '__package__',\n '__path__',\n '__spec__',\n '_api',\n '_meta',\n '_utils',\n 'alexnet',\n 'convnext',\n 'convnext_base',\n 'convnext_large',\n 'convnext_small',\n 'convnext_tiny',\n 'densenet',\n 'densenet121',\n 'densenet161',\n 'densenet169',\n 'densenet201',\n 'detection',\n 'efficientnet',\n 'efficientnet_b0',\n 'efficientnet_b1',\n 'efficientnet_b2',\n 'efficientnet_b3',\n 'efficientnet_b4',\n 'efficientnet_b5',\n 'efficientnet_b6',\n 'efficientnet_b7',\n 'efficientnet_v2_l',\n 'efficientnet_v2_m',\n 'efficientnet_v2_s',\n 'get_model',\n 'get_model_builder',\n 'get_model_weights',\n 'get_weight',\n 'googlenet',\n 'inception',\n 'inception_v3',\n 'list_models',\n 'maxvit',\n 'maxvit_t',\n 'mnasnet',\n 'mnasnet0_5',\n 'mnasnet0_75',\n 'mnasnet1_0',\n 'mnasnet1_3',\n 'mobilenet',\n 'mobilenet_v2',\n 'mobilenet_v3_large',\n 'mobilenet_v3_small',\n 'mobilenetv2',\n 'mobilenetv3',\n 'optical_flow',\n 'quantization',\n 'regnet',\n 'regnet_x_16gf',\n 'regnet_x_1_6gf',\n 'regnet_x_32gf',\n 'regnet_x_3_2gf',\n 'regnet_x_400mf',\n 'regnet_x_800mf',\n 'regnet_x_8gf',\n 'regnet_y_128gf',\n 'regnet_y_16gf',\n 'regnet_y_1_6gf',\n 'regnet_y_32gf',\n 'regnet_y_3_2gf',\n 'regnet_y_400mf',\n 'regnet_y_800mf',\n 'regnet_y_8gf',\n 'resnet',\n 'resnet101',\n 'resnet152',\n 'resnet18',\n 'resnet34',\n 'resnet50',\n 'resnext101_32x8d',\n 'resnext101_64x4d',\n 'resnext50_32x4d',\n 'segmentation',\n 'shufflenet_v2_x0_5',\n 'shufflenet_v2_x1_0',\n 'shufflenet_v2_x1_5',\n 'shufflenet_v2_x2_0',\n 'shufflenetv2',\n 'squeezenet',\n 'squeezenet1_0',\n 'squeezenet1_1',\n 'swin_b',\n 'swin_s',\n 'swin_t',\n 'swin_transformer',\n 'swin_v2_b',\n 'swin_v2_s',\n 'swin_v2_t',\n 'vgg',\n 'vgg11',\n 'vgg11_bn',\n 'vgg13',\n 'vgg13_bn',\n 'vgg16',\n 'vgg16_bn',\n 'vgg19',\n 'vgg19_bn',\n 'video',\n 'vision_transformer',\n 'vit_b_16',\n 'vit_b_32',\n 'vit_h_14',\n 'vit_l_16',\n 'vit_l_32',\n 'wide_resnet101_2',\n 'wide_resnet50_2']"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(models)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "alexnet = models.AlexNet()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wuyuxian/anaconda3/envs/AI/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/wuyuxian/anaconda3/envs/AI/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet101_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet101_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "resnet = models.resnet101(pretrained=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "data": {
      "text/plain": "ResNet(\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu): ReLU(inplace=True)\n  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (layer2): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (3): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (layer3): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (3): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (4): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (5): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (6): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (7): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (8): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (9): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (10): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (11): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (12): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (13): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (14): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (15): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (16): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (17): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (18): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (19): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (20): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (21): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (22): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (layer4): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n)"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "img = Image.open(\"horse.jpg\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "img.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "#预处理管道传递图像\n",
    "img_t = preprocess(img)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "#按照网络期望的方式对输入的张量进行重塑、裁剪和归一化处理\n",
    "import torch\n",
    "batch_t = torch.unsqueeze(img_t, 0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "data": {
      "text/plain": "ResNet(\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu): ReLU(inplace=True)\n  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (layer2): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (3): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (layer3): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (3): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (4): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (5): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (6): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (7): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (8): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (9): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (10): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (11): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (12): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (13): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (14): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (15): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (16): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (17): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (18): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (19): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (20): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (21): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (22): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (layer4): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n)"
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet.eval()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[-3.0750e+00, -1.5513e+00,  1.8620e+00,  5.0177e-02,  6.4221e-01,\n         -1.0961e-01,  1.0240e+00,  2.9839e+00, -1.1159e+00,  1.8814e+00,\n         -4.2087e+00, -3.6604e+00, -3.0206e+00, -5.5697e+00, -1.7747e+00,\n         -3.0089e+00, -3.7074e+00, -1.0540e+00, -1.9684e+00, -4.5826e+00,\n         -5.3042e+00,  1.0134e+00, -1.9532e+00,  1.4473e+00, -3.4471e+00,\n         -2.6357e+00, -2.9162e+00, -2.4023e+00, -1.0720e+00, -3.1659e+00,\n         -2.3239e+00, -2.8332e+00, -3.2967e+00, -7.6156e-01,  3.5111e-01,\n         -3.0553e+00, -1.2116e+00, -2.0969e+00,  1.1910e-01,  2.0926e+00,\n         -2.9356e+00,  1.3984e+00, -8.0891e-01,  8.0323e-03, -1.9727e+00,\n         -1.6779e+00, -8.3520e-01, -2.0912e+00, -1.5653e+00, -2.1709e+00,\n         -3.7323e+00,  4.1284e+00, -1.5014e+00, -2.6137e+00, -2.7159e+00,\n         -1.0277e+00, -2.4023e+00, -2.5533e+00, -3.3681e+00, -1.1756e+00,\n         -1.1515e+00, -1.4894e+00, -1.1030e+00, -2.7464e-01, -3.2600e-01,\n         -8.5655e-01, -2.8436e-01, -1.7093e+00, -5.8457e-01, -1.5341e+00,\n         -2.9875e+00,  3.9421e-01, -3.3114e+00, -1.3478e+00, -5.1481e-01,\n         -2.0205e+00, -1.4381e+00, -1.7273e+00, -1.0198e+00,  2.9198e+00,\n         -3.8887e-01, -4.0395e+00, -2.0980e+00, -1.1353e+00, -8.6785e-01,\n         -3.9361e+00, -2.3260e+00, -5.9777e-01,  3.4348e+00, -6.3948e-01,\n         -3.1372e+00, -1.8866e+00, -1.3329e+00, -2.4243e+00, -2.2202e+00,\n         -3.8689e+00, -2.6816e+00, -3.4828e+00, -4.5295e+00, -3.8893e+00,\n         -3.4818e+00, -3.6096e-01, -2.8020e+00, -1.6504e+00, -3.1293e+00,\n         -1.3613e+00, -1.0350e+00,  2.4519e+00, -8.8727e-02, -1.2199e+00,\n         -1.5925e+00,  2.1715e-01,  3.1667e+00, -2.0410e+00, -1.9258e+00,\n         -5.3918e-01, -2.3997e+00, -3.6458e-01,  6.5780e-02, -8.8028e-02,\n         -8.5191e-01,  7.7175e-01,  3.5242e+00,  1.2089e+00,  1.3336e+00,\n          2.7358e-01,  1.3982e-02, -2.2161e+00, -3.5878e+00, -1.5578e+00,\n          1.3404e+00, -2.4794e+00, -2.5471e+00, -3.6010e+00, -2.5262e+00,\n         -1.8135e+00, -2.0481e+00, -3.4969e+00, -7.7189e-01, -2.9251e+00,\n         -4.3594e+00, -3.3245e+00, -3.0636e+00, -3.1646e+00, -2.3336e+00,\n         -3.1291e+00, -1.2650e+00,  4.9699e-01, -1.8190e+00, -4.8654e-01,\n          2.6956e+00,  1.6119e-01, -1.0832e+00, -7.2186e-01, -1.7079e-01,\n         -1.1810e+00,  9.2798e-01, -1.0906e+00, -1.3997e+00,  6.1357e+00,\n          2.2050e+00,  2.6326e-01, -2.3821e+00,  1.7681e+00, -2.0726e+00,\n         -1.0746e+00, -2.1874e-01, -1.2125e+00,  4.9753e+00, -2.5560e-02,\n         -8.9830e-01,  1.9147e+00,  1.1626e+00,  2.5842e+00, -3.3994e+00,\n         -2.4081e+00,  3.6312e+00,  2.6332e-01,  1.6199e+00, -5.3945e-01,\n         -1.1913e+00, -1.7462e+00, -2.1878e+00, -7.5914e-02,  1.1508e+00,\n          2.3227e+00,  3.9447e-01,  2.7887e-01, -3.4437e+00, -6.1372e-01,\n         -3.7406e+00, -7.3369e-01, -1.3605e+00,  1.5639e+00, -4.5863e+00,\n          4.8267e-01, -1.5303e+00, -9.2522e-01, -1.6569e+00, -2.0847e+00,\n          9.1434e-01, -2.9495e-01,  5.9295e-02, -8.8672e-01,  1.3612e+00,\n         -3.4943e-01, -2.1694e-01,  1.4501e+00, -5.2249e-01,  3.4245e-01,\n         -1.1053e-01,  5.2656e+00, -3.7451e-01,  5.4699e+00, -9.8902e-02,\n          1.6712e+00, -2.5142e+00, -2.6736e+00,  1.0728e+00, -2.9349e-01,\n         -8.1207e-03, -5.2871e-01, -8.8389e-01, -1.6241e+00, -3.0415e-02,\n         -1.6898e+00,  1.4535e-01,  1.7194e-01, -1.0854e+00, -8.6170e-01,\n         -1.0957e+00, -9.0096e-01, -6.9100e-01, -2.0212e-01,  5.3522e-01,\n         -1.5626e+00,  3.7701e-01,  1.2013e+00,  1.2662e+00, -1.4038e+00,\n         -1.3377e+00, -1.5437e+00,  3.6889e+00,  1.0906e-01, -1.8563e-02,\n         -2.3702e+00,  2.3577e+00, -1.2688e+00, -2.0292e+00, -1.8506e+00,\n         -1.3019e+00,  9.6455e-01, -2.0126e+00,  1.7124e+00, -8.8646e-01,\n         -1.7835e+00,  9.6510e-01, -1.8887e+00,  1.3338e-01, -9.2292e-01,\n          2.8036e-01, -2.0238e+00, -1.7793e+00, -1.4091e+00, -1.5242e+00,\n         -9.4466e-01, -1.6806e+00,  5.5000e-01,  3.0472e+00, -3.0593e+00,\n         -4.4863e+00, -1.5339e+00, -3.5488e+00,  4.2532e-01, -4.8657e-01,\n          4.4974e-01,  6.2478e-01, -3.6067e+00, -4.0159e+00, -4.6237e+00,\n         -2.3436e+00, -7.7122e-01, -5.2142e-03, -2.1061e+00, -3.2589e+00,\n         -9.3272e-01, -1.0939e-01, -4.1050e+00, -3.4494e-01, -3.8369e+00,\n         -1.0618e+00, -1.9031e-01,  1.6645e-01, -9.8830e-01, -2.7577e+00,\n         -4.5406e+00, -2.6407e+00, -3.0116e+00, -3.6406e+00, -2.3455e+00,\n          1.1695e+00, -1.5896e+00,  2.1810e-01, -1.2481e+00, -1.2115e+00,\n         -8.4251e-01,  7.0040e-01, -2.4268e+00, -1.3596e+00, -1.8975e+00,\n          2.4237e+00, -8.9608e-01,  9.4215e-02,  1.0284e+00,  1.1809e+00,\n         -4.9151e-02, -1.0243e+00, -1.6952e+00, -2.7461e+00,  1.9428e+00,\n         -7.4414e-01, -1.9029e+00, -2.9699e+00, -7.6947e-01, -2.5906e+00,\n         -5.6614e-01, -2.6049e+00,  1.4583e+00, -1.1266e+00, -1.0220e+00,\n         -5.3992e+00, -4.3626e+00, -2.4492e+00, -2.5227e+00, -2.3142e+00,\n         -3.2847e+00, -3.8041e+00, -3.5325e+00, -3.4042e+00,  1.5192e+01,\n          4.9099e+00, -8.4690e-01, -2.2834e+00,  1.2908e+00,  7.0971e-01,\n          3.8477e+00,  6.0061e-01,  2.7413e-01, -2.3174e-02,  5.2063e-01,\n          5.1507e-02,  5.5243e+00,  2.5524e+00,  2.4408e+00,  1.0983e+01,\n          4.1613e+00, -1.9235e+00, -2.6738e+00, -2.7022e+00, -9.1556e-01,\n         -3.0842e+00, -2.1025e+00, -3.3759e+00, -2.2175e+00, -2.8203e+00,\n          2.5552e+00, -1.7274e+00, -2.1645e+00, -3.1953e+00, -1.2565e+00,\n         -3.8676e+00, -2.5297e+00, -9.9279e-01, -2.2395e+00, -1.8654e+00,\n         -2.3220e+00, -3.2231e+00, -2.9501e+00, -2.5846e+00, -1.6061e+00,\n         -3.2395e+00, -2.5925e+00, -3.1984e+00, -3.0638e+00, -2.8851e+00,\n          1.1858e+00,  2.7632e+00, -2.9238e+00, -6.1821e+00,  1.1122e+00,\n         -1.1659e+00, -1.9683e-01, -2.6951e+00, -1.0515e+00,  1.7569e-01,\n         -9.6223e-01,  9.1243e-02, -1.6772e+00,  2.4359e+00,  9.8311e-01,\n         -1.4479e+00,  1.0668e+00, -7.9831e-01, -1.8066e-01, -1.9093e-01,\n          1.3752e+00, -2.3148e+00,  2.1029e-01,  5.8131e-01,  1.9322e+00,\n          7.8975e-01, -2.9774e+00,  1.9257e+00,  1.3804e+00,  9.1614e-01,\n          1.0445e+00,  7.6031e-02,  4.8830e+00, -1.9347e+00,  1.4989e+00,\n         -3.0185e-01,  2.5539e+00,  2.5845e+00, -9.5934e-01, -7.6554e-01,\n          5.3374e-01,  4.8749e-01,  7.2344e+00,  1.3764e+00,  3.0077e+00,\n          1.8600e+00, -1.9697e+00, -3.6190e-01,  1.9939e+00,  1.0079e+00,\n          4.8547e-01,  3.3023e-01,  3.6927e-01,  1.7372e+00,  2.7116e+00,\n          1.5943e+00,  2.0828e+00,  4.9601e-02, -2.5994e-01,  2.1669e+00,\n          5.6205e+00, -1.3834e+00,  6.2366e+00, -2.4156e+00, -2.9600e+00,\n         -9.2810e-01,  7.2004e-02, -1.0152e+00,  2.2874e-01, -5.1365e-01,\n         -1.4431e+00,  2.3879e+00,  1.1451e+00, -1.3737e-01,  3.2402e+00,\n         -7.9572e-02,  4.4241e+00,  1.5412e+00,  5.2474e+00,  2.1874e+00,\n          2.9592e-01, -2.8460e+00,  1.0732e+00, -9.1683e-02,  1.8944e-01,\n          1.6858e+00,  1.1351e+00, -4.9349e-01, -1.0014e+00, -2.3213e-01,\n          9.7594e-01,  7.0146e+00, -9.9237e-02, -9.7216e-03, -4.0850e-02,\n          5.7326e-01, -1.4266e+00, -2.3005e+00, -6.9925e-01,  5.3698e-01,\n         -2.4511e+00,  7.4426e-01,  1.5724e+00,  2.4352e+00,  2.4334e+00,\n          2.6970e+00,  2.0699e+00, -1.5062e+00,  5.8687e-01, -3.7817e-01,\n         -2.0911e-01, -1.6059e+00, -2.6941e+00,  1.2617e+00,  2.0815e-01,\n          1.3054e+00,  2.2517e+00,  1.2663e+00,  2.3335e+00,  3.8308e+00,\n          1.7731e-01,  2.5003e-01, -2.1123e+00, -5.0252e-01,  2.1800e+00,\n          1.8855e+00,  8.0081e-01, -1.3612e+00,  1.8138e+00,  7.4010e+00,\n          8.3886e+00, -1.5953e+00,  2.6224e+00,  4.0716e+00,  1.4029e+00,\n         -2.5506e-01, -5.7980e-01,  1.5447e+00,  2.8967e+00,  4.8671e+00,\n         -3.0649e-01,  3.6613e-01, -1.2653e+00, -1.0294e-01,  1.9058e+00,\n          1.7223e+00, -6.3794e-01,  6.0246e-01,  1.2477e+00,  2.1230e-01,\n         -3.2168e+00,  2.1306e+00, -1.0414e+00,  3.2032e-01, -6.9174e-01,\n          1.2688e+00,  2.1939e+00,  1.0272e+00,  4.4735e+00, -1.4281e+00,\n          8.0613e-01, -1.4580e+00, -2.2250e+00, -5.1685e-01, -8.5385e-01,\n         -1.7215e+00, -1.1968e+00,  1.5952e+00, -4.8083e-01,  7.3523e-01,\n          2.2725e+00, -7.5357e-01,  1.8556e+00, -5.4269e-01,  1.3727e+00,\n          4.0489e+00, -1.9854e-01,  3.0434e+00, -3.2237e+00, -3.1463e+00,\n          9.0915e-01,  6.8912e-01, -1.9772e+00,  1.9118e+00,  3.4415e-02,\n          2.8775e+00,  2.5178e+00,  4.1408e+00, -9.4754e-01,  2.1666e-01,\n          2.5225e-01, -7.1369e-01, -5.1859e-01, -5.6189e-02, -1.5330e+00,\n         -9.4445e-01,  1.8515e+00,  7.5625e-01, -1.1524e+00,  2.6623e+00,\n          3.0024e+00, -6.0678e-01,  5.5498e-01,  5.7069e-01,  2.0623e+00,\n         -5.6235e-01,  2.3278e+00, -1.7420e+00,  6.1891e-01,  1.0272e+00,\n          6.7515e-01,  1.8143e+00,  2.5875e+00,  1.6700e+00,  1.9951e+00,\n          3.4296e+00,  4.4214e-01,  3.0352e+00,  6.4473e+00,  2.0444e+00,\n          1.7176e-01, -8.8241e-01,  1.3754e+00,  5.5337e-01, -3.5221e-01,\n          1.3465e+00, -4.6918e-01, -9.4055e-01, -1.3598e-01, -8.8630e-01,\n          3.3203e+00,  2.9750e+00, -2.8820e-01, -1.0495e-01,  7.3694e-01,\n         -1.3669e-01, -6.0076e-01, -7.4012e-01, -1.9961e+00, -7.8648e-02,\n          3.1549e+00, -1.1565e+00, -2.0196e+00,  1.8609e+00, -1.6194e+00,\n          2.2997e-02,  4.3261e+00,  1.1124e+00,  1.3879e+00, -4.4306e-02,\n         -4.4670e-02,  1.6297e+00,  7.6040e-01,  7.0351e+00,  4.3387e+00,\n         -3.8484e+00,  3.0385e+00,  4.5599e-01,  2.7613e+00, -7.5243e-01,\n          6.9392e-01,  5.7654e-01,  1.9915e+00, -1.5713e+00,  7.2345e-01,\n          1.4579e+00, -1.8761e+00,  2.3680e+00,  3.3101e+00,  3.2894e-02,\n          3.1222e+00, -7.4757e-01, -4.1019e-01, -6.3981e-02,  1.5323e+00,\n          1.1861e+00,  7.3260e-02, -3.3710e+00,  5.5556e-01, -1.8705e-01,\n          2.1537e+00,  1.5427e+00, -7.6321e-01, -3.1494e+00, -9.9123e-01,\n          1.7107e+00,  3.6151e+00,  1.9702e-01, -1.1572e+00, -4.4807e-01,\n         -1.3285e+00,  4.8184e+00,  1.1757e+00,  1.9837e+00, -7.0967e-01,\n          2.6796e+00,  2.5608e-01,  1.2107e-01, -8.0804e-01, -2.5191e-01,\n         -2.3462e+00,  6.4578e-01, -2.9495e+00, -2.4907e+00, -1.5412e+00,\n          1.6928e+00,  3.9888e+00,  4.0478e-01,  2.9625e+00, -7.6056e-01,\n         -2.6578e-01,  5.5946e-01,  2.2658e+00,  2.7697e+00,  6.0591e-01,\n          9.1674e-01,  5.6176e+00,  2.0617e+00,  8.8620e-01,  1.9682e+00,\n         -5.9904e-01,  4.2906e-03,  7.9312e-01,  1.6939e+00, -9.3259e-01,\n          8.5479e-01,  1.2919e+00,  1.0567e+00, -1.7262e+00, -1.2456e+00,\n          9.0132e-01,  2.3885e+00,  2.0494e+00,  2.7574e+00,  2.8313e+00,\n          2.6578e+00,  3.3781e-01,  1.1143e-02,  2.6258e+00,  1.4263e+00,\n          1.6218e+00, -2.5966e+00,  1.4596e+00,  1.5618e+00,  5.0365e-01,\n          3.8589e+00,  2.7506e+00, -4.1463e+00,  3.6608e+00, -1.5613e+00,\n          3.5580e+00,  5.4558e-01,  4.8722e-01,  1.3343e+00,  3.8732e-01,\n          2.9325e+00,  6.6884e-02, -3.2220e+00,  1.8568e+00,  1.8632e+00,\n         -1.2192e+00,  2.3586e+00,  4.1371e+00, -1.1685e+00,  6.0892e-01,\n          4.7988e-01,  5.2548e-01,  1.2528e+00,  7.1308e-01, -9.0775e-01,\n          8.8670e-01,  5.6468e+00,  4.4055e-01, -9.7612e-01,  3.5916e-01,\n          7.2978e-01, -1.1477e+00,  2.4725e-01, -5.3624e-01,  1.1936e+00,\n         -1.8164e-01,  4.4913e-01, -1.1512e+00,  1.4731e+00,  2.0021e+00,\n          2.3343e+00, -1.4432e+00,  9.8647e-01,  1.4186e+00,  1.3455e+00,\n          3.0729e+00,  1.7749e+00,  4.5983e-01,  1.4486e+00, -1.8267e-01,\n          3.7667e-01, -1.9175e-02,  7.0736e-01,  1.4271e+00,  9.1005e-01,\n          1.1345e-01,  1.1097e-01,  5.8322e+00,  2.0596e-01, -4.7573e-01,\n         -3.0609e-01,  4.1385e-01,  1.8722e+00, -2.1163e-02,  1.6529e-01,\n          3.2811e+00,  4.6143e-01,  1.2704e+00, -2.6612e+00,  8.6243e-01,\n         -1.5959e+00,  4.3128e+00, -2.9303e-01, -1.4849e-01,  2.8642e-01,\n          4.5768e+00,  1.4004e+00,  1.4074e+00,  4.8198e+00, -1.4915e+00,\n         -2.5037e+00, -9.0462e-01, -1.5153e+00,  1.3249e-01, -2.1861e-01,\n         -1.0807e+00, -2.3508e-01,  1.7687e+00,  1.8585e+00,  1.6702e+00,\n         -2.0829e+00, -1.9025e+00,  4.2789e+00,  8.3268e-01, -1.5365e+00,\n         -6.3364e-01,  2.3218e+00, -2.7621e+00,  1.5995e+00, -2.2486e+00,\n          2.5377e+00,  9.2816e-01, -7.3530e-02,  7.7825e-01,  6.4658e-02,\n         -7.5900e-01,  3.0159e+00,  2.4554e+00,  5.8307e+00, -1.6824e+00,\n         -3.2903e-01,  3.2652e+00,  5.6007e+00,  5.0335e+00, -1.3420e+00,\n          6.7207e-01,  2.0730e-02,  4.5274e-01, -2.3044e+00,  3.0012e+00,\n          3.9064e-01,  1.2119e+00,  5.3570e-01,  2.4730e-01,  1.2687e+00,\n          7.2493e-01,  3.6507e+00, -3.1249e-01,  2.0225e+00, -1.1968e+00,\n         -7.9175e-01,  1.7902e-01,  3.0972e+00,  2.1260e-01,  5.8845e-01,\n          3.3056e+00,  3.1143e+00,  3.6509e-01,  2.0409e+00,  1.9006e+00,\n         -5.7958e-02, -1.1438e+00,  1.7218e+00,  3.7281e-01, -3.8666e+00,\n          1.0455e+00,  2.5631e+00,  1.4630e-01, -1.6742e+00,  1.0804e+00,\n          3.2906e+00,  8.0822e-02, -1.4049e+00,  1.5020e+00, -6.5573e-01,\n          4.5598e-01, -2.0197e+00, -3.4481e+00, -2.2627e+00, -3.7967e-01,\n          5.9329e+00, -3.4863e+00,  1.9577e+00, -3.2115e-01, -1.1420e+00,\n          2.6128e+00, -8.6592e-01,  1.4363e+00,  4.9180e+00,  3.6195e+00,\n          1.8978e+00, -4.2550e-03,  1.4313e+00,  2.3247e+00, -2.6128e-01,\n          8.2543e-01, -1.3406e+00,  3.5917e-01,  2.0049e+00, -3.1745e+00,\n          5.3281e-01, -3.7463e-01,  3.1904e+00,  3.5361e+00, -7.4821e-01,\n          8.3279e-01,  3.4904e+00,  3.6010e+00,  8.3358e-01,  2.5018e+00,\n         -4.0404e-01,  2.2977e+00, -2.3045e+00, -9.0535e-01, -1.0839e-01,\n         -2.1400e+00, -4.2126e+00,  5.7152e-01,  6.8873e-01,  2.5422e+00,\n          1.4085e+00, -1.2299e+00,  2.8714e+00, -3.1171e+00, -4.0287e-01,\n         -9.9689e-01, -6.9389e-01, -2.1643e+00,  3.5438e-02, -1.8121e+00,\n         -1.9239e+00, -1.3584e+00, -1.4418e+00,  3.2409e-01, -1.7719e+00,\n          1.4102e+00, -1.3120e+00,  1.8728e-01,  1.7307e-01, -7.8479e-01,\n         -5.8427e-01, -1.0353e+00, -1.3336e+00, -1.5496e+00,  7.7492e-01,\n         -2.4286e-01, -2.8524e+00, -8.1228e-01,  2.2731e+00, -2.3090e+00,\n          3.3097e+00, -7.5211e-01, -2.8971e+00, -4.5026e+00, -3.4429e+00,\n         -1.9211e+00,  1.3943e+00,  5.4338e-01,  2.3462e+00,  8.5777e-01,\n          2.8477e+00,  3.5467e+00,  4.3124e+00,  2.3068e+00, -2.3932e-01,\n          2.3755e+00,  4.0610e-01,  3.6122e+00,  5.9470e+00, -5.6418e-01,\n          1.3033e-01,  3.7408e+00, -2.5032e+00,  3.6211e+00,  2.6381e+00,\n         -2.2926e+00, -2.7876e+00,  1.0792e+00, -2.2052e+00, -1.2095e+00,\n         -8.0939e-01, -1.6949e+00, -1.5961e+00,  1.2628e+00, -2.6245e+00,\n         -7.1069e-01, -7.9061e-01, -3.6457e+00,  9.7368e-01,  2.7518e-01]],\n       grad_fn=<AddmmBackward0>)"
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = resnet(batch_t)\n",
    "out"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "# 加载1000个标签\n",
    "with open(\"imagenet_classes.txt\") as f:\n",
    "    labels = [line.strip() for line in f.readlines()]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "# 此处的索引并不是一个数字，而是一个一位张量\n",
    "_,index = torch.max(out,1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "data": {
      "text/plain": "('sorrel', 98.04434204101562)"
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percentage = torch.nn.functional.softmax(out,dim=1)[0]*100\n",
    "labels[index[0]],percentage[index[0]].item()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "data": {
      "text/plain": "[('sorrel', 98.04434204101562),\n ('Arabian camel, dromedary, Camelus dromedarius', 1.4567869901657104),\n ('cowboy hat, ten-gallon hat', 0.10884644836187363),\n ('cowboy boot', 0.04054182022809982),\n ('barrel, cask', 0.03432077541947365)]"
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_,indices = torch.sort(out,descending=True)\n",
    "[(labels[idx],percentage[idx].item()) for idx in indices[0][:5]]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
